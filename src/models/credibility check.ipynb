{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b89849e1-b269-42f5-a4a7-6051270ae7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Detected change in classified_reddit_posts.json! Re-running credibility check...\n",
      "‚úÖ Processed 0 posts. 0 are credible.\n",
      "\n",
      "‚úÖ All posts are now stored permanently in all_processed_posts.json\n",
      "‚è≥ No changes detected. Waiting...\n",
      "‚è≥ No changes detected. Waiting...\n",
      "‚è≥ No changes detected. Waiting...\n",
      "üîÑ Detected change in classified_reddit_posts.json! Re-running credibility check...\n",
      "\n",
      "Processing post: Severe Flooding in Mumbai!\n",
      "  +1: Author posts in limited subreddits\n",
      "  +1: Author has 7 recent posts\n",
      "  +3: Intent classified as 'awareness'\n",
      "  Final Score: 5\n",
      "\n",
      "‚úÖ Processed 1 posts. 0 are credible.\n",
      "\n",
      "‚úÖ All posts are now stored permanently in all_processed_posts.json\n",
      "üîÑ Detected change in classified_reddit_posts.json! Re-running credibility check...\n",
      "\n",
      "Processing post: Severe Flooding in Mumbai!\n",
      "  +1: Author posts in limited subreddits\n",
      "  +1: Author has 7 recent posts\n",
      "  +3: Intent classified as 'awareness'\n",
      "  Final Score: 5\n",
      "\n",
      "\n",
      "Processing post: Kansas Hit by Massive Tornado!\n",
      "  +1: Author posts in limited subreddits\n",
      "  +1: Author has 7 recent posts\n",
      "  +5: Intent classified as 'damage_report'\n",
      "  Final Score: 7\n",
      "\n",
      "\n",
      "Processing post: Cyclone Yaas Makes Landfall!\n",
      "  +1: Author posts in limited subreddits\n",
      "  +1: Author has 7 recent posts\n",
      "  +2: Intent classified as 'prevention'\n",
      "  Final Score: 4\n",
      "\n",
      "\n",
      "Processing post: An earthquake hits Mumbai\n",
      "  +1: Author posts in limited subreddits\n",
      "  +1: Author has 7 recent posts\n",
      "  +3: Intent classified as 'awareness'\n",
      "  Final Score: 5\n",
      "\n",
      "\n",
      "Processing post: Massive Earthquake Hits Los Angeles!\n",
      "  +1: Author posts in limited subreddits\n",
      "  +1: Author has 7 recent posts\n",
      "  +3: Intent classified as 'informational'\n",
      "  Final Score: 5\n",
      "\n",
      "\n",
      "Processing post: Massive Earthquake Hits Los Angeles!\n",
      "  +1: Author posts in limited subreddits\n",
      "  +1: Author has 7 recent posts\n",
      "  +2: Intent classified as 'question'\n",
      "  Final Score: 4\n",
      "\n",
      "\n",
      "Processing post: Road accident in pune\n",
      "  +1: Account age > 180 days (242 days)\n",
      "  +1: Author posts in limited subreddits\n",
      "  +1: Author has 10 recent posts\n",
      "  +3: Intent classified as 'informational'\n",
      "  Final Score: 6\n",
      "\n",
      "‚úÖ Processed 7 posts. 2 are credible.\n",
      "\n",
      "‚úÖ All posts are now stored permanently in all_processed_posts.json\n",
      "üîÑ Detected change in classified_reddit_posts.json! Re-running credibility check...\n",
      "\n",
      "Processing post: Severe Flooding in Mumbai!\n",
      "  +1: Author posts in limited subreddits\n",
      "  +1: Author has 7 recent posts\n",
      "  +3: Intent classified as 'awareness'\n",
      "  Final Score: 5\n",
      "\n",
      "\n",
      "Processing post: Kansas Hit by Massive Tornado!\n",
      "  +1: Author posts in limited subreddits\n",
      "  +1: Author has 7 recent posts\n",
      "  +5: Intent classified as 'damage_report'\n",
      "  Final Score: 7\n",
      "\n",
      "\n",
      "Processing post: Cyclone Yaas Makes Landfall!\n",
      "  +1: Author posts in limited subreddits\n",
      "  +1: Author has 7 recent posts\n",
      "  +2: Intent classified as 'prevention'\n",
      "  Final Score: 4\n",
      "\n",
      "\n",
      "Processing post: An earthquake hits Mumbai\n",
      "  +1: Author posts in limited subreddits\n",
      "  +1: Author has 7 recent posts\n",
      "  +3: Intent classified as 'awareness'\n",
      "  Final Score: 5\n",
      "\n",
      "\n",
      "Processing post: Massive Earthquake Hits Los Angeles!\n",
      "  +1: Author posts in limited subreddits\n",
      "  +1: Author has 7 recent posts\n",
      "  +3: Intent classified as 'informational'\n",
      "  Final Score: 5\n",
      "\n",
      "\n",
      "Processing post: Massive Earthquake Hits Los Angeles!\n",
      "  +1: Author posts in limited subreddits\n",
      "  +1: Author has 7 recent posts\n",
      "  +2: Intent classified as 'question'\n",
      "  Final Score: 4\n",
      "\n",
      "\n",
      "Processing post: Road accident in pune\n",
      "  +1: Account age > 180 days (242 days)\n",
      "  +1: Author posts in limited subreddits\n",
      "  +1: Author has 10 recent posts\n",
      "  +3: Intent classified as 'informational'\n",
      "  Final Score: 6\n",
      "\n",
      "‚úÖ Processed 7 posts. 2 are credible.\n",
      "\n",
      "‚úÖ All posts are now stored permanently in all_processed_posts.json\n",
      "‚è≥ No changes detected. Waiting...\n",
      "‚è≥ No changes detected. Waiting...\n",
      "‚è≥ No changes detected. Waiting...\n",
      "‚è≥ No changes detected. Waiting...\n",
      "‚è≥ No changes detected. Waiting...\n",
      "‚è≥ No changes detected. Waiting...\n",
      "‚è≥ No changes detected. Waiting...\n",
      "‚è≥ No changes detected. Waiting...\n",
      "‚è≥ No changes detected. Waiting...\n",
      "‚è≥ No changes detected. Waiting...\n",
      "‚è≥ No changes detected. Waiting...\n",
      "‚è≥ No changes detected. Waiting...\n",
      "‚è≥ No changes detected. Waiting...\n",
      "‚è≥ No changes detected. Waiting...\n",
      "‚è≥ No changes detected. Waiting...\n",
      "‚è≥ No changes detected. Waiting...\n",
      "‚è≥ No changes detected. Waiting...\n",
      "‚è≥ No changes detected. Waiting...\n",
      "‚è≥ No changes detected. Waiting...\n",
      "‚è≥ No changes detected. Waiting...\n",
      "‚è≥ No changes detected. Waiting...\n",
      "‚è≥ No changes detected. Waiting...\n",
      "‚è≥ No changes detected. Waiting...\n",
      "‚è≥ No changes detected. Waiting...\n",
      "‚è≥ No changes detected. Waiting...\n",
      "‚è≥ No changes detected. Waiting...\n",
      "‚è≥ No changes detected. Waiting...\n",
      "‚è≥ No changes detected. Waiting...\n",
      "‚è≥ No changes detected. Waiting...\n",
      "‚è≥ No changes detected. Waiting...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 201\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚ö†Ô∏è classified_reddit_posts.json not found. Retrying...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 201\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import os\n",
    "import praw\n",
    "import re\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(\"../config/cred.env\")\n",
    "\n",
    "# Reddit API Credentials\n",
    "CLIENT_ID = os.getenv(\"CLIENT_ID\")\n",
    "CLIENT_SECRET = os.getenv(\"CLIENT_SECRET\")\n",
    "USERNAME = os.getenv(\"REDDIT_USERNAME\")\n",
    "PASSWORD = os.getenv(\"REDDIT_PASSWORD\")\n",
    "USER_AGENT = os.getenv(\"USER_AGENT\")\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=CLIENT_ID,\n",
    "    client_secret=CLIENT_SECRET,\n",
    "    username=USERNAME,\n",
    "    password=PASSWORD,\n",
    "    user_agent=USER_AGENT\n",
    ")\n",
    "\n",
    "# Subreddits related to disasters\n",
    "relevant_subreddits = [\n",
    "    \"r/aircrashinvestigation\", \"r/StormComing\", \"r/NaturalDisastersToday\",\n",
    "    \"r/naturesfury\", \"r/DisasterUpdate\", \"r/hurricane\", \"r/Earthquakes\",\n",
    "    \"r/tornado\", \"r/caraccidents\"\n",
    "]\n",
    "\n",
    "def get_author_history(author_name):\n",
    "    \"\"\"Fetches the author's account history for credibility scoring.\"\"\"\n",
    "    try:\n",
    "        redditor = reddit.redditor(author_name)\n",
    "        account_age = (time.time() - redditor.created_utc) / (60 * 60 * 24)  # Age in days\n",
    "        recent_posts = list(redditor.submissions.new(limit=10))  # Last 10 posts\n",
    "        subreddit_counts = {post.subreddit.display_name: 1 for post in recent_posts}\n",
    "        multiple_subreddits = len(subreddit_counts) > 5\n",
    "\n",
    "        return {\n",
    "            \"account_age_days\": account_age,\n",
    "            \"num_recent_posts\": len(recent_posts),\n",
    "            \"posts_in_multiple_subreddits\": multiple_subreddits,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching author history: {e}\")\n",
    "        return None\n",
    "\n",
    "def classify_post_intent(post):\n",
    "    \"\"\"Classifies post intent based on keywords.\"\"\"\n",
    "    keywords = {\n",
    "        \"question\": [\"who\", \"what\", \"where\", \"when\", \"why\", \"how\", \"?\"],\n",
    "        \"scam\": [\"donate\", \"fundraiser\", \"help fund\", \"support victims\"],\n",
    "        \"political\": [\"government failure\", \"blame\", \"policy\", \"should have prevented\"],\n",
    "        \"emotional\": [\"thoughts and prayers\", \"stay strong\", \"heartbreaking\"],\n",
    "        \"informational\": [\"guide\", \"analysis\", \"report\", \"information\"],\n",
    "        \"damage_report\": [\"casualties\", \"damage\", \"affected area\"],\n",
    "        \"prevention\": [\"prepare\", \"emergency kit\", \"evacuation\", \"safety measures\"],\n",
    "        \"awareness\": [\"earthquake\", \"flood\", \"hurricane\", \"disaster\", \"storm\", \"alert\"],\n",
    "    }\n",
    "\n",
    "    text = (post.get(\"title\", \"\") + \" \" + post.get(\"selftext\", \"\")).lower()\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    flair = (post.get(\"link_flair_text\") or \"\").lower()\n",
    "\n",
    "    for intent, words in keywords.items():\n",
    "        if any(word in text for word in words) or flair == intent:\n",
    "            return intent\n",
    "\n",
    "    return \"unknown\"\n",
    "\n",
    "def calculate_credibility(post):\n",
    "    \"\"\"Calculates credibility score of a Reddit post with debugging output.\"\"\"\n",
    "    score = 0\n",
    "    print(f\"\\nProcessing post: {post.get('title', 'No Title')}\")\n",
    "\n",
    "    author_data = get_author_history(post[\"author\"]) if post.get(\"author\") else None\n",
    "    intent = classify_post_intent(post)\n",
    "\n",
    "    if author_data:\n",
    "        if author_data[\"account_age_days\"] > 180:\n",
    "            score += 1\n",
    "            print(f\"  +1: Account age > 180 days ({int(author_data['account_age_days'])} days)\")\n",
    "        if not author_data[\"posts_in_multiple_subreddits\"]:\n",
    "            score += 1\n",
    "            print(\"  +1: Author posts in limited subreddits\")\n",
    "        if author_data[\"num_recent_posts\"] > 5:\n",
    "            score += 1\n",
    "            print(f\"  +1: Author has {author_data['num_recent_posts']} recent posts\")\n",
    "\n",
    "    if post.get(\"author_premium\"):\n",
    "        score += 1\n",
    "        print(\"  +1: Author has premium membership\")\n",
    "\n",
    "    if post.get(\"subreddit_name_prefixed\") in relevant_subreddits:\n",
    "        score += 1\n",
    "        print(f\"  +1: Post in relevant subreddit {post['subreddit_name_prefixed']}\")\n",
    "    elif post.get(\"subreddit_subscribers\", 0) > 10000:\n",
    "        score += 1\n",
    "        print(f\"  +1: Subreddit has {post['subreddit_subscribers']} subscribers\")\n",
    "\n",
    "    intent_scores = {\n",
    "        \"question\": 2, \"scam\": -3, \"political\": -2, \"emotional\": 0,\n",
    "        \"informational\": 3, \"damage_report\": 5, \"prevention\": 2, \"awareness\": 3\n",
    "    }\n",
    "    \n",
    "    intent_score = intent_scores.get(intent, 0)\n",
    "    score += intent_score\n",
    "    print(f\"  {intent_score:+d}: Intent classified as '{intent}'\")\n",
    "\n",
    "    if post.get(\"num_comments\", 0) > 5:\n",
    "        score += 1\n",
    "        print(f\"  +1: Post has {post['num_comments']} comments\")\n",
    "    if post.get(\"upvote_ratio\", 0) > 0.7 and post.get(\"ups\", 0) > 50:\n",
    "        score += 2\n",
    "        print(f\"  +2: Upvote ratio {post['upvote_ratio']}, {post['ups']} upvotes\")\n",
    "    if post.get(\"edited\"):\n",
    "        score -= 1\n",
    "        print(\"  -1: Post has been edited\")\n",
    "    if post.get(\"mod_reports\") or post.get(\"user_reports\"):\n",
    "        score -= 2\n",
    "        print(\"  -2: Post has been reported by users or moderators\")\n",
    "    if post.get(\"removed_by\") or post.get(\"banned_by\"):\n",
    "        score -= 3\n",
    "        print(\"  -3: Post has been removed or banned\")\n",
    "\n",
    "    print(f\"  Final Score: {score}\\n\")\n",
    "    return score\n",
    "\n",
    "\n",
    "def process_credible_posts():\n",
    "    \"\"\"Loads classified posts, evaluates credibility, and saves credible posts.\"\"\"\n",
    "    try:\n",
    "        with open(\"classified_reddit_posts.json\", \"r\") as file:\n",
    "            reddit_posts = json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ö†Ô∏è classified_reddit_posts.json not found. Waiting for new data...\")\n",
    "        return\n",
    "\n",
    "    credible_posts = []\n",
    "    threshold = 6\n",
    "\n",
    "    for post in reddit_posts:\n",
    "        post[\"credibility_score\"] = calculate_credibility(post)\n",
    "        if post[\"credibility_score\"] >= threshold:\n",
    "            credible_posts.append(post)\n",
    "\n",
    "    with open(\"credible_reddit_posts.json\", \"w\") as outfile:\n",
    "        json.dump(credible_posts, outfile, indent=4)\n",
    "\n",
    "    print(f\"‚úÖ Processed {len(reddit_posts)} posts. {len(credible_posts)} are credible.\")\n",
    "\n",
    "    # Load the latest credible posts\n",
    "    with open(\"credible_reddit_posts.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "        new_posts = json.load(file)\n",
    "    \n",
    "    # Check if the master file exists\n",
    "    master_file = \"all_processed_posts.json\"\n",
    "\n",
    "    if os.path.exists(master_file):\n",
    "        with open(master_file, \"r\", encoding=\"utf-8\") as file:\n",
    "            all_posts = json.load(file)\n",
    "    else:\n",
    "        all_posts = []\n",
    "\n",
    "    # Convert existing post URLs to a set to prevent duplicates\n",
    "    existing_post_urls = {post[\"url\"] for post in all_posts}\n",
    "\n",
    "    # Add only new posts that aren't already in the master file\n",
    "    for post in new_posts:\n",
    "        if post[\"url\"] not in existing_post_urls:\n",
    "            all_posts.append(post)\n",
    "\n",
    "    # Save back to the master file\n",
    "    with open(master_file, \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(all_posts, file, indent=4)\n",
    "\n",
    "    print(\"\\n‚úÖ All posts are now stored permanently in all_processed_posts.json\")\n",
    "\n",
    "\n",
    "# Monitor changes in classified_reddit_posts.json\n",
    "last_mod_time = 0\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        current_mod_time = os.path.getmtime(\"classified_reddit_posts.json\")\n",
    "\n",
    "        if current_mod_time != last_mod_time:\n",
    "            print(\"üîÑ Detected change in classified_reddit_posts.json! Re-running credibility check...\")\n",
    "            process_credible_posts()\n",
    "            last_mod_time = current_mod_time\n",
    "        else:\n",
    "            print(\"‚è≥ No changes detected. Waiting...\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ö†Ô∏è classified_reddit_posts.json not found. Retrying...\")\n",
    "\n",
    "    time.sleep(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
